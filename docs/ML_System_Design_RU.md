# Machine Learning System Design Document - Demand Forecasting

## 1. Цели и предпосылки
### 1.1. Бизнес-цели
Supermegaretaillite — это маркетплейс, охватывающий тысячи товаров потребительской и офисной электроники. Эти категории имеют свои уникальные характеристики, циклы спроса и предложения, которые необходимо учитывать категориям менеджеров при планировании закупок. Прежде чем продавать любой товар, Supermegaretaillite должен закупить его в необходимых объемах у поставщика. Из-за ограниченного складского пространства, менеджер по категориям должен учитывать несколько важных аспектов при закупке товара:
- **Out-of-stock (отсутствие на складе)**: Когда нужного товара нет на складе, а следующая поставка будет только через несколько дней. В итоге клиент обращается к конкурентам, что приводит к упущенной прибыли.
- **Overstock (излишки на складе)**: Когда товар "зависает" и не продается, приходится "ликвидировать" его, значительно снижая цену и продавая ниже себестоимости, чтобы он не занимал место на складе.
- **Упущенная прибыль**: Это потерянный доход из-за ситуаций с отсутствием товара на складе.
- **Оборот товара**: Время от поступления товара на склад до его отправки клиенту.

Цель данного проекта по разработке ML-сервиса — увеличить прибыль Supermegaretaillite и оптимизировать работу категорийных менеджеров. В настоящее время их подход заключается в расчете средних продаж товара за последние n дней и умножении на количество дней, на которое делается закупка — этот метод не учитывает сезонность, историю спроса и предложения. В связи с этим руководство Supermegaretaillite приняло решение инвестировать средства в разработку автоматизированной системы управления закупками у поставщиков, включающей разработку ML-сервиса для прогнозирования спроса.

### 1.2 Анализ текущего процесса
На данный момент заказ товаров осуществляется вручную с помощью категорийного менеджера на основе его интуиции. Этот метод плохо масштабируется и имеет ряд недостатков, таких как болезнь или увольнение менеджера.

### 1.3. Преимущества использования ML
Наше ML-решение автоматизирует процесс закупок, учитывая историю продаж, сезонность и другие факторы, влияющие на спрос. В теории, это увеличит прибыль и оптимизирует работу категорийных менеджеров, а также устранит человеческий фактор, такой как болезнь или увольнение менеджера.

### 1.4. Оценка затрат
Наш бюджет на разработку состоит из:
1. Зарплата ML-инженера: 100 000 рублей в месяц
2. Аренда облачных вычислительных ресурсов (сервера, PostgreSQL, S3): 5 000 рублей в месяц

### 1.5. Бизнес-требования и ограничения
#### 1.5.1 Бизнес-требования
- **Точность**: Модель должна снизить показатели Out-of-stock и Overstock на 10%. В настоящее время Out-of-stock составляет 15-20%, а Overstock — 20-30%, что увеличит оборот товаров и повысит прибыль на 10%.
- **Время отклика**: Сервис должен отвечать на запросы в течение 3-5 секунд.
- **Операционная надежность**: Сервис должен быть доступен 24/7, также должны создаваться раз в сутки резервные копии всех баз данных и отправляться в два независимых хранилища.


#### 1.5.2 Бизнес-ограничения
- **Сроки**: Первая версия сервиса должна быть готова через 1 месяц.

#### 1.5.3 Шаги по интеграции MVP

- **Поиск оптимальной ML-модели**: Провести исследование и определить оптимальную ML-модель для прогнозирования спроса.
- **Сбор данных и организация хранения**: Создать базу данных в PostgreSQL и S3 для хранения данных для обучения и тестирования моделей.
- **Обучение модели**: Обучить модель на собранных данных.
- **Тестирование**: Написать интеграционные, юнит и функциональные тесты для сервиса, чтобы предотвратить проблемы в продакшене.
- **Разработка интерфейса Streamlit**: Разработать интерфейс Streamlit для категорийных менеджеров для взаимодействия с сервисом.
- **Запуск MVP**: Запустить MVP для ограниченного магазина и ограниченного количества товаров.


#### 1.5.4 Критерии успешности MVP

- **Время отклика**: Сервис должен отвечать на запросы в течение 3-5 секунд.
- **Операционная надежность**: Сервис должен быть доступен 24/7, также должны создаваться раз в сутки резервные копии всех баз данных и отправляться в два независимых хранилища.
- **Точность сервиса**: Сервис должен снизить показатели Out-of-stock и Overstock на 10%. В настоящее время Out-of-stock составляет 15-20%, а Overstock — 20-30%, что увеличит оборот товаров и повысит прибыль на 10%.

### 1.6. Объем проекта и исключения
#### 1.6.1 Объем
- Разработка и интерпретация надежной модели для прогнозирования спроса.
- Интеграция сервиса с базой данных PostgreSQL и хранилищем S3.
- Разработка ML-сервиса для прогнозирования спроса для Supermegaretaillite в виде приложения Streamlit.
- Тестирование и мониторинг.

#### 1.6.2 Исключения
- Не включает оптимизацию скорости работы модели и сервиса.
- Не включает в себя разработку системы управления поставками и заказами.
- Не влюкчает в себя эксперименты с CatBoost, Prophet, ETNA, feature engineering и другие улучшения модели.


## 2. Методология

### 2.1. Определение проблемы
Основные проблемы бизнеса — это отсутствие товара на складе (Out-of-stock) и избыток товара (Overstock), что приводит к низкому оборачиваемости и упущенной прибыли. Для решения этой проблемы необходимо разработать модель прогнозирования спроса, которая учитывает все эти факторы.

В этой версии MVP мы будем использовать квантильную регрессию для прогнозирования спроса т.к бизнес интересует не столько прогноз спроса, сколько конкретные проблемы: отсутствие товара на складе, избыток товара и упущенная прибыль. Также нам нужно управлять уровнем уверености в прогнозах, чтобы категорийные менеджеры могли принимать решения на основе риска, что как раз можно сделать с помощью квантильной регрессии.

При прогнозировании мы неизбежно сталкиваемся с ошибками. Для разных товаров эти ошибки могут различаться. Поэтому важно учитывать разные аспекты "распределения спроса" для каждого товара. В одних случаях переоценка критична, в других — недооценка.

Для решения этих проблем мы будем прогнозировать не только средние продажи за следующие N дней, но и квантильные прогнозы. Каждый квантиль представляет собой прогноз с разным уровнем уверенности:

- 0.1 квантиль — "пессимистичный" прогноз (в 90% случаев прогноз ниже фактических продаж);
- 0.5 квантиль — "консервативный" прогноз (в 50% случаев фактические продажи выше, в 50% — ниже);
- 0.9 квантиль — "оптимистичный" прогноз (в 90% случаев прогноз выше фактических продаж).

Например, для товара 1 квантильные прогнозы продаж на следующие две недели могут быть такими:

- 0.1 квантиль (пессимистичный прогноз) — 3 единицы (с вероятностью 90% продажи составят 3 единицы или больше);
- 0.5 квантиль (консервативный прогноз) — 5 единиц;
- 0.9 квантиль (оптимистичный прогноз) — 8 единиц (с вероятностью 90% продажи составят 8 единиц или меньше).

Это позволяет категорийным менеджерам принимать решения о закупках, основываясь на потребностях и уровнях риска.

Кроме того, мы используем статистические методы, такие как бутстреппинг, для оценки величины ошибки и уверенности в прогнозах. Бутстреппинг позволяет создавать доверительные интервалы, которые предоставляют информацию о диапазоне значений. Это значительно полезнее, чем точечная оценка среднего значения, которая не учитывает величину ошибки.

### 2.2. Выбор метрик

#### 2.2.1. Оффлайн метрики
Оффлайн метрики позволяют оценить качество модели на исторических данных до ее развертывания в реальном времени.

- **Quantile Loss (Квантильная потеря)**: Основная функция потерь, которую мы будем оптимизировать. Эта метрика оценивает качество прогнозов для различных квантилей (0.1, 0.5, 0.9) и наказывает недооценку и переоценку в зависимости от выбранного квантилия. Формула для квантильной потери:
  \[
  L(y, p; q) = q \cdot \max(y - p, 0) + (1 - q) \cdot \max(p - y, 0)
  \]
  где:
  - \( y \) — фактическое значение,
  - \( p \) — прогнозируемое значение,
  - \( q \) — квантиль (0.1, 0.5, 0.9).

- **RMSE**: Среднеквадратичная ошибка. Эта метрика позволяет оценить общую точность модели. RMSE показывает, насколько сильно прогнозируемые значения отклоняются от фактических значений. Мы также будем использовать эту метрику как прокси для сравнения нашей начальной модели (квантильная регрессия) с другими моделями.

- **Coverage Probability (Вероятность покрытия)**: Доля фактических значений продаж, которые попадают в интервал между прогнозируемыми квантилями 0.1 и 0.9. Это важно для оценки надежности интервалов прогнозов.

#### 2.2.2. Онлайн метрики
- **Prediction Interval Coverage Probability (PICP)**: Доля фактических значений, которые попадают в предсказанный интервал между квантилями 0.1 и 0.9. Это аналогично метрике вероятности покрытия, но измеряется в реальном времени.

- **Real-time Quantile Loss**: Аналогично оффлайн квантильной потере, но измеряется в реальном времени. Эта метрика позволяет оценить точность модели в условиях текущих продаж.

- **Uptime**: Время, в течение которого сервис был доступен. Это важная метрика т.к. мы должны отслеживать доступен ли сервис и если нет — принимать меры для его восстановления.

#### 2.2.3. Бизнес метрики
Бизнес метрики оценивают влияние модели на ключевые показатели эффективности бизнеса.

- **Out-of-stock Rate (Процент отсутствия товара)**: Доля времени, когда товар отсутствует на складе. Снижение этой метрики указывает на улучшение прогнозов спроса и, соответственно, на лучшее управление запасами.

- **Overstock Rate (Процент излишков)**: Доля времени, когда товар в избытке на складе. Снижение этой метрики указывает на более точные прогнозы спроса и снижение затрат на хранение.

- **Упущенная прибыль**: Сумма упущенного дохода из-за отсутствия товара на складе. Эта метрика позволяет оценить прямое влияние точности прогноза на доход компании.

- **Оборачиваемость товара**: Более высокий оборот указывает на эффективное управление запасами, что приводит к снижению затрат и улучшению денежного потока.

### 2.3. Определение объектов и таргета
Для каждой строки в наборе данных (строка представляет собой товар-день) мы будем рассчитывать следующие признаки:
- Среднее количество продаж за последние N дней.
- X-й квантиль продаж за последние N дней.

Для таргета мы будем рассчитывать:
- Общее количество продаж за следующие N дней.

### 2.4. Сбор данных
Таблица demand_orders_status (статусы заказов):
- order_id – уникальный номер заказа.
- status_id – идентификатор статуса.
- status – название статуса.

Таблица demand_orders (таблица заказов):
- order_id – уникальный номер заказа.
- timestamp – дата и время, когда заказ был размещен.
- sku_id – уникальный идентификатор товара.
- sku – название товара.
- price – цена товара, которая остается неизменной в течение дня.
- qty – количество товара в заказе.
- status_id – идентификатор статуса заказа.

### 2.5. Подготовка данных
Атомарной единицей набора данных будет товар-день – (sku, день). Соответственно, каждый прогноз будет делаться для каждого момента времени (каждого дня) и каждого товара на определенный период в будущем (1-2-3-4 недели).

Для расчета как агрегатов будущих продаж (целей), так и агрегатов прошлых продаж (признаков), нам нужны ежедневные агрегаты продаж.

Для каждого товара-дня мы будем рассчитывать общее количество продаж (qty) и получим следующую таблицу:
- день – день.
- sku_id – уникальный идентификатор товара.
- sku – название товара.
- price – цена товара на текущий день.
- qty – общее количество продаж товара на текущий день.

Однако простое значение qty недостаточно, поэтому мы будем рассчитывать необходимые признаки и целевые переменные с использованием оконных функций: скользящее окно в прошлое для расчета признаков и скользящее окно в будущее для расчета таргета.

## 3. Обучение пилотной версии

### 3.1. Архитектура решения ML
#### 3.1.1. Базовое решение
Базовым решением будет модель квантильной регрессии, как говорилось ранее. Мы будем использовать функцию потерь квантиля для оптимизации модели для различных квантилей (0.1, 0.5, 0.9). Модель будет прогнозировать квантильные значения продаж на следующие N дней.

Наш пайплайн обучения выглядит следующим образом:

![pipeline](../images/Demand_Forencast_Pipeline.jpg)

#### 3.1.2. Улучшения после базового решения
После обучения базовой модели мы оценим ее производительность и внесем улучшения на основе результатов. Мы будем экспериментировать с различными моделями, такими как CatBoost, Prophet и ETNA чтобы найти лучшую модель для прогнозирования спроса. Мы также будем экспериментировать с различными признаками, такими как цена, скидки и акции, чтобы улучшить производительность модели. Но не в этой версии MVP.

### 3.2. Предварительное обеспечение качества
Перед запуском сервиса мы проведем серию тестов, чтобы убедиться в качестве модели и сервиса. Мы протестируем производительность модели на исторических данных и оценим ее точность, вероятность покрытия и квантильную потерю. Мы также протестируем время отклика и надежность сервиса, чтобы убедиться, что он соответствует бизнес-требованиям. Также мы попросим категорийных менеджеров оценить сервис и предоставить обратную связь по его точности, стабильности и полезности.

### 3.3. Метод оценки пилотного проекта
- **Функциональные требования** - сервис должен быть доступен 24/7 и отвечать на запросы в течение 3-5 секунд в Streamlit.
- **Нефункциональные требования** - сервис должен быть надежным и минимизировать сбои и ошибки в прогнозах согласно метрикам, описанным выше на исторических данных (за один прошлый год).

### 3.4. Критерии успешности пилотного проекта
Если мы сможем подтвердить пункты из раздела 1.5.4 на исторических данных, то пилотный проект считается успешным.

### 3.5. Инфраструктура и масштабируемость
Мы будем использовать следующую инфраструктуру для пилотного проекта:
- **Сервис**: Под нашу задачу нужно будет два сервера: один будет сожержать сам ML-сервис, базы данных, web-интерфейс, а другой будет использоваться для мониторинга и хранения резервных копий. И тот и другой сервер будет иметь 2 ядра CPU, 4 ГБ оперативной памяти и 16 ГБ хранилища.

### 3.6. Мониторинг
Мы будем мониторить производительность сервиса, используя инструменты Grafana, Prometheus и Uptime Kuma для отслеживания метрик из раздела 2.2.

### 3.7. Требования к эксплуатации системы
Система должна быть доступна 24/7 и отвечать на запросы в течение 3-5 секунд. Сервис должен быть надежным и минимизировать сбои и ошибки в прогнозах согласно метрикам, обсужденным выше на исторических данных (за один прошлый год). Раз в день будет создаваться резервная копия всех баз данных и отправляться на другой независимый сервер. Также сервис должен автоматически поднимать контейнеры при перезагрузке.

### 3.8. Безопасность системы

#### 3.8.1. Шифрование данных
Мы будем использовать HTTPS для безопасной передачи данных и шифровать хранящиеся данные, чтобы предотвратить несанкционированный доступ и ограничение доступа к серверам по белым IP. Также мы можем защитить базы данных от SQL-инъекций, используя ORM (Object-Relational Mapping) и подготовленные выражения.

#### 3.8.2. Аутентификация и управление доступом
Доступ к сервису должен быть ограничен: мы контролируем выдачу root-пароля от сервера (он должен быть известен только архитектору и ML-инженеру), во всех остальных случаях мы выдаем SSH-ключ, который можем удалить в любое время, тем самым ограничивая доступ. Далее мы можем использовать HashiCorp Vault для управления доступом к учетным данным и секретам.

#### 3.8.3. Безопасность учетных данных
Чувствительные учетные данные не будут храниться открыто в кодовых репозиториях. Мы будем использовать переменные окружения и безопасные инструменты управления секретами для безопасного обращения с учетными данными. Также в будущем мы можем использовать HashiCorp Vault для управления секретами.

### 3.9. Риски
- **Качество данных**: Плохое качество данных может привести к неточным прогнозам. Мы решим эту проблему путем очистки и предварительной обработки данных перед обучением модели и написанию тестов для проверки качества данных.
- **Производительность модели**: Модель может давать неточные прогнозы, что приведет к ситуациям с отсутствием или избытком товаров на складе. Мы решим эту проблему, мониторя работу модели и не пропуская модель в продакшен, если она не превысила показатели, установленные в разделе метрик на исторических данных.
- **Надежность сервиса**: Критическая ошибка может привести к потере всех данных на сервере. Мы решим эту проблему, создавая резервные копии всех баз данных и отправляя их в два независимых хранилища раз в день.
- **Ошибки в прогнозах**: Неточные прогнозы могут привести к упущенной прибыли и избыткам товаров на складе. Мы решим эту проблему, мониторя работу модели и не пропуская модель в продакшен, если она не превысила показатели, установленные в разделе метрик на исторических данных. Также мы будем использовать сервис на одном магазине и ограниченное количество товаров для оценки точности и производительности модели перед полномасштабным запуском для всех магазинов и товаров.

## 4. Реализация пилотного проекта

### 4.1. Этапы реализации MVP
Пилотный проект будет включать ограниченный магазин и ограниченное количество товаров. Это позволит оценить точность и производительность сервиса в реальных условиях перед полномасштабным запуском.

#### 4.1.1. Прототипирование и предварительный эксперимент
Мы начнем с сбора данных и обработку их из PostgreSQL и S3 для обучения модели на исторических данных. Затем мы разработаем интерфейс Streamlit для категорийных менеджеров для взаимодействия с сервисом.

#### 4.1.2. Тестирование
Мы протестируем сервис на исторических данных и оценим его производительность на основе обсужденных метрик. Мы также попросим категорийных менеджеров оценить сервис и предоставить обратную связь по его точности, стабильности и полезности. Также мы напишем интеграционные (проверка взаимодействия между компонентами), юнит (проверка отдельных компонентов) и функциональные (проверка функциональности) тесты для сервиса, чтобы предотвратить проблемы в продакшене.

#### 4.1.3. Запуск MVP
После тестирования сервиса на исторических данных и получения обратной связи от категорийных менеджеров мы запустим сервис для ограниченного магазина и ограниченного количества товаров. Мы будем мониторить производительность сервиса и оценивать его точность, вероятность покрытия и квантильную потерю. Мы также будем следить за временем отклика и надежностью сервиса, чтобы убедиться, что он соответствует бизнес-требованиям.

#### 4.1.4. Анализ обратной связи
После запуска MVP мы проанализируем обратную связь от категорийных менеджеров и оценим производительность сервиса на основе обсужденных метрик. Мы также будем мониторить производительность сервиса и оценивать его точность, вероятность покрытия и квантильную потерю. Мы также будем следить за временем отклика и надежностью сервиса, чтобы убедиться, что он соответствует бизнес-требованиям.
